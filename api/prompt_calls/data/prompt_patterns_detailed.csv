pattern_name,pattern_family,primary_purpose,core_mechanism,input_fields,output_fields,workflow_structure,control_flags,typical_use_cases,risks_and_misuses,example_prompt_skeleton
Alternative Approaches,exploration_and_comparison,Surface multiple viable ways to accomplish a task or solve a problem and compare them so the user can choose among them.,"Given a description of a task or problem X, the model lists several alternative approaches to achieving X. It can optionally include the originally implied approach, compare pros and cons across options, and ask the user which approach to follow next.","[{""name"": ""task_X_description"", ""description"": ""Natural-language description of the user’s task or problem."", ""required"": true}, {""name"": ""include_original_approach_bool"", ""description"": ""If true, the model also describes the approach implied by the user’s initial request and includes it in the comparison."", ""required"": false}, {""name"": ""compare_contrast_bool"", ""description"": ""If true, the model compares pros and cons of each alternative approach."", ""required"": false}, {""name"": ""ask_user_to_choose_bool"", ""description"": ""If true, the model ends by asking the user which approach to follow."", ""required"": false}]","[{""name"": ""approach_list"", ""description"": ""List of named alternative approaches for accomplishing X.""}, {""name"": ""comparison_table"", ""description"": ""Optional structured comparison (pros / cons / conditions) between approaches.""}, {""name"": ""follow_up_question"", ""description"": ""Optional question that asks the user to select an approach or refine their goal.""}]","{""phases"": [{""name"": ""problem_restatement"", ""description"": ""Restate or clarify the task X in neutral language.""}, {""name"": ""approach_generation"", ""description"": ""Generate several distinct solution strategies for X.""}, {""name"": ""comparison"", ""description"": ""Compare approaches on criteria such as cost, speed, risk, quality.""}, {""name"": ""selection_prompt"", ""description"": ""Optionally prompt the user to pick an approach or combination.""}]}","{""max_approaches"": ""Maximum number of approaches to list (e.g. 3–7)."", ""require_diversity"": ""If true, discourage near-duplicate approaches."", ""include_original_approach"": ""Whether to model the approach implied by the initial request."", ""include_comparison"": ""Whether to add a structured comparison section.""}","[""Prompt engineering and rewording tasks."", ""Design and architecture brainstorming."", ""Choosing between modeling or implementation strategies."", ""Exploring alternative plans for a project.""]","[""Too many low-quality approaches that overwhelm the user."", ""Superficial comparisons that overstate differences."", ""Model hallucinating approaches that are not actually feasible.""]","You are an expert assistant. I will describe a task.

Task: {task_X_description}

1. List {N} distinct, high-quality approaches to accomplishing this task.
{% if include_original_approach_bool %}   Include the approach implied by my original request as one of the options.
{% endif %}{% if compare_contrast_bool %}2. Compare the approaches in terms of advantages, disadvantages, and when each is most appropriate.
{% endif %}{% if ask_user_to_choose_bool %}3. End by asking me which approach I would like to pursue next.
{% endif %}"
Ask for Input,interaction_loop,Ensure the model explicitly requests a specific input from the user before starting its main behavior.,"The prompt defines a role or behavior for the model and instructs it to ask the user for a particular piece of input X (e.g., a document, question, list, or goal) before it begins performing that behavior. The model repeats this request whenever it needs a new instance of X.","[{""name"": ""task_description"", ""description"": ""Description of the ongoing behavior the model should perform once it has the required input."", ""required"": true}, {""name"": ""input_label_X"", ""description"": ""Name or description of the required input from the user (e.g. 'email chain', 'text to translate', 'PDF')."", ""required"": true}]","[{""name"": ""initial_input_request"", ""description"": ""Clear question asking the user to provide X before starting.""}, {""name"": ""loop_prompt"", ""description"": ""Standard phrasing used whenever another input X is needed for the next cycle.""}]","{""phases"": [{""name"": ""role_declaration"", ""description"": ""Model summarizes its function for the user.""}, {""name"": ""first_input_request"", ""description"": ""Model asks for the first instance of X.""}, {""name"": ""process_input"", ""description"": ""For each received X, the model applies the task behavior and returns a result.""}, {""name"": ""repeat_request"", ""description"": ""After producing a result, the model asks for the next X or whether to stop.""}]}","{""require_confirmation"": ""If true, the model confirms the task description before asking for input."", ""input_size_hint"": ""Optional guidance on the expected size/length of X."", ""stop_keyword"": ""Optional keyword the user can send to terminate the loop.""}","[""Iterative summarization of multiple emails or documents."", ""Batch translation or paraphrasing."", ""Stepwise troubleshooting where each step needs new information.""]","[""Model may forget to ask for the next input and instead hallucinate it."", ""Ambiguous description of X can confuse users about what to provide."", ""If X can contain sensitive data, must be paired with privacy guidance.""]","From now on, you will {task_description}.
Before you start, ask me for the first {input_label_X}.
After you finish processing each {input_label_X}, ask me if I want to process another one or stop."
Fact Check List,quality_control,"Make the model enumerate key factual statements in its output that should be verified, improving transparency and enabling downstream fact-checking.","Whenever the model generates content, it also produces a list of fundamental facts from that content. These facts are those whose incorrectness would significantly undermine the answer. The list is inserted at a specified position in the output such as the end.","[{""name"": ""fact_list_position"", ""description"": ""Where to place the fact list (e.g. 'at the end', 'under a heading', 'in a separate section')."", ""required"": true}, {""name"": ""fact_granularity_hint"", ""description"": ""Optional guidance on how detailed the facts should be (e.g. '5–10 bullet points')."", ""required"": false}]","[{""name"": ""main_content"", ""description"": ""The primary answer, explanation, or summary.""}, {""name"": ""fact_check_list"", ""description"": ""A bullet list of core factual claims that should be externally verified.""}]","{""phases"": [{""name"": ""content_generation"", ""description"": ""Model produces the main answer or narrative.""}, {""name"": ""fact_extraction"", ""description"": ""Model scans its own output and extracts key factual statements.""}, {""name"": ""fact_list_formatting"", ""description"": ""Model formats these facts as a list and inserts it at the specified position.""}]}","{""min_fact_count"": ""Minimum number of facts to list."", ""max_fact_count"": ""Maximum number of facts to list."", ""fact_style"": ""Required style for the facts (e.g. short sentences, bullet points).""}","[""Research article summaries that need external validation."", ""Explanatory essays or reports prepared for decision makers."", ""Any content that will be routed into an automated fact-checking pipeline.""]","[""Model may miss important implicit assumptions that should also be checked."", ""Low-quality fact lists that restate trivial points instead of key claims."", ""Users may treat unverified facts as fully reliable.""]","Write the requested answer or summary.

Then, under the heading 'Key Facts to Verify', list {N} factual statements from your own output that are most critical to its correctness. Place this section {fact_list_position}."
Menu Actions,interaction_loop,Define a small command language where specific phrases from the user trigger well-defined actions by the model.,"The prompt enumerates a set of commands (strings) and their corresponding actions. Whenever the user types command X, the model executes the mapped action Y. After each response, the model asks the user what to do next, keeping the loop open.","[{""name"": ""commands_and_actions"", ""description"": ""Mapping from user command phrases to the actions the model should take."", ""required"": true}, {""name"": ""final_prompt_for_next_action"", ""description"": ""Optional standard phrasing asking the user what to do next after each action."", ""required"": false}]","[{""name"": ""action_result"", ""description"": ""Result of executing the chosen action.""}, {""name"": ""next_action_prompt"", ""description"": ""Question prompting the user for the next command.""}]","{""phases"": [{""name"": ""command_explanation"", ""description"": ""Model lists the available commands and what each does.""}, {""name"": ""command_execution"", ""description"": ""For each user message, model matches it to a command and performs the associated action.""}, {""name"": ""loop_prompt"", ""description"": ""Model asks for the user's next command.""}]}","{""strict_command_matching"": ""If true, act only when user input matches a known command exactly/closely."", ""allow_free_text"": ""If true, allow the user to send natural language instead of commands and handle it gracefully."", ""show_help_command"": ""Optional command (e.g. 'help') to re-list available actions.""}","[""Simple dashboards inside chat (e.g. project management commands)."", ""Interactive tools for editing, reviewing, or tagging content."", ""Data exploration or note-taking with a small set of verbs.""]","[""Ambiguity if user input partially matches several commands."", ""Unexpected behavior if the model improvises commands that were not defined."", ""User may forget available actions without periodic reminders.""]","You support the following commands:
{commands_and_actions}

Whenever I type one of these commands, perform the described action and show me the result. At the end of each response, say:
""What would you like to do next?"""
Meta Language Creation,meta_language,"Create a custom shorthand or symbolic language where special tokens map to longer meanings, actions, or structures.","The prompt defines one or more meta-tokens (e.g. functions, tags, markers) and specifies what each should mean. The model interprets any future appearance of these tokens according to these definitions when generating or parsing text.","[{""name"": ""meta_phrases_mapping"", ""description"": ""Mapping from meta tokens (e.g. 'variations(x)', 'Task X [Task Y]') to their intended meanings or operations."", ""required"": true}, {""name"": ""scope_of_meta_language"", ""description"": ""Where the meta-language applies (all messages, only user messages, only model outputs, or both)."", ""required"": false}]","[{""name"": ""interpreted_output"", ""description"": ""Model output that applies the meta-language rules to expand or act upon the meta tokens.""}]","{""phases"": [{""name"": ""definition_phase"", ""description"": ""Define each meta token and its meaning.""}, {""name"": ""usage_phase"", ""description"": ""User and model begin using the meta tokens in dialogue or commands.""}, {""name"": ""resolution_phase"", ""description"": ""Model resolves meta tokens into their full meanings during generation.""}]}","{""allow_new_tokens"": ""Whether new meta tokens can be introduced dynamically."", ""expand_inline"": ""If true, expand meta tokens directly in output; otherwise, explain them.""}","[""Custom prompt DSLs for power users."", ""Concise task specification in technical or research workflows."", ""Graph or dependency notations for project management.""]","[""User confusion if token meanings are not documented or remembered."", ""Model misinterpreting similar natural-language strings as meta tokens."", ""Meta language collisions across different sessions or tools.""]","We are going to define a small meta-language.
Here are the meta tokens and what they mean:
{meta_phrases_mapping}

From now on, whenever I use one of these tokens, interpret it according to its definition and respond accordingly."
Recipe Pattern,planning_and_decomposition,"Turn a high-level goal, plus a few known steps, into a complete, ordered plan.","Given a goal X and a partial list of steps known by the user, the model constructs a full ordered sequence of steps, fills in missing ones, and optionally flags unnecessary steps or risks.","[{""name"": ""goal_X"", ""description"": ""High-level goal the user wants to achieve."", ""required"": true}, {""name"": ""known_steps_list"", ""description"": ""List of steps the user already believes are required, in any order."", ""required"": true}, {""name"": ""identify_unnecessary_steps_bool"", ""description"": ""If true, the model indicates which of the known steps may be unnecessary."", ""required"": false}]","[{""name"": ""ordered_steps"", ""description"": ""Complete ordered list of steps needed to achieve the goal.""}, {""name"": ""step_annotations"", ""description"": ""Optional notes on dependencies, risks, or prerequisites.""}]","{""phases"": [{""name"": ""goal_parsing"", ""description"": ""Clarify and restate the goal X.""}, {""name"": ""step_completion"", ""description"": ""Generate missing steps and order both existing and new steps logically.""}, {""name"": ""review_and_flagging"", ""description"": ""Optionally mark unnecessary or high-risk steps and suggest improvements.""}]}","{""max_step_count"": ""Upper bound on steps to keep plans manageable."", ""group_into_phases"": ""If true, cluster steps into phases such as 'Preparation', 'Execution', 'Follow-up'.""}","[""Planning a research project or experiment pipeline."", ""Creating a study schedule or skill-learning roadmap."", ""Outlining major milestones for a business or engineering project.""]","[""Over-simplified plans that skip important real-world constraints."", ""Overly detailed plans that become hard to follow."", ""Plans that assume unrealistic resources or timelines.""]","I want to achieve the following goal:
{goal_X}

I already know that I need to do these steps:
{known_steps_list}

Please create a complete, ordered sequence of steps that will help me reach the goal. Fill in any missing steps.
{% if identify_unnecessary_steps_bool %}Also indicate if any of my listed steps are unnecessary or redundant.
{% endif %}"
Semantic Filter,filtering_and_redaction,"Filter or redact parts of text that match a semantic condition, such as a type of sensitive information or irrelevant content.","Given some source text and a semantic filter condition X, the model returns a version of the text where all content satisfying X has been removed or transformed according to the specification.","[{""name"": ""filter_condition_X"", ""description"": ""Semantic property that determines what should be removed, e.g. 'any PII', 'specific names', 'redundant content', or 'costs above a threshold'."", ""required"": true}, {""name"": ""retention_guidelines"", ""description"": ""Optional description of what must be preserved (e.g. structure, line count)."", ""required"": false}]","[{""name"": ""filtered_text"", ""description"": ""The resulting text after removing elements that satisfy X.""}]","{""phases"": [{""name"": ""condition_interpretation"", ""description"": ""Model interprets the filter condition in the context of the text.""}, {""name"": ""filter_application"", ""description"": ""Model removes or transforms segments that match the condition.""}, {""name"": ""structural_cleanup"", ""description"": ""Model cleans up the remaining text to ensure readability and coherence.""}]}","{""strictness_level"": ""How aggressively to filter content (low, medium, high)."", ""preserve_formatting"": ""If true, preserve layout markers such as headings and bullet points.""}","[""Redacting PII before storing user data."", ""Removing redundant or boilerplate text from emails or logs."", ""Filtering out off-topic content from research notes.""]","[""Over-filtering important information by misinterpreting the condition."", ""Under-filtering sensitive data in ambiguous cases."", ""Changing the meaning of the text when too much is removed.""]","Here is some text. Remove all content that matches the following condition:
{filter_condition_X}

Return only the filtered version of the text.
{% if retention_guidelines %}Make sure to follow these constraints on what should remain:
{retention_guidelines}
{% endif %}"
Tail Generation,interaction_flow,"Standardize how responses end, such as always adding a disclaimer or a follow-up question, to guide the next interaction.","The model is instructed that every response must end with a specific tail segment, such as repeating key options, adding a disclaimer, or asking the user a question about next steps.","[{""name"": ""tail_Y_or_followup_X"", ""description"": ""Description of the required tail content (e.g. disclaimer text, list of options, or a question asking what to do next)."", ""required"": true}]","[{""name"": ""main_content"", ""description"": ""Primary response to the user’s request.""}, {""name"": ""tail_segment"", ""description"": ""Final standardized segment appended to the response.""}]","{""phases"": [{""name"": ""core_response"", ""description"": ""Model generates the main content normally.""}, {""name"": ""tail_attachment"", ""description"": ""Model appends the required tail content verbatim or according to a pattern.""}]}","{""tail_separator"": ""String used to separate main content from tail (e.g. '\\n\\n---\\n')."", ""enforce_consistency"": ""If true, the tail wording must remain identical across responses.""}","[""Agents that always end with a follow-up question to maintain conversation."", ""Safety or legal disclaimers appended to certain types of content."", ""Stepwise workflows that always ask what to do next.""]","[""Users may ignore repeated disclaimers, reducing perceived impact."", ""The tail may become misleading if context changes but the template does not."", ""For long tails, verbosity can annoy users.""]","Whenever you respond to me, first generate the main answer.
Then, at the very end of your response, append the following tail:
{tail_Y_or_followup_X}"
Template Pattern,format_control,Force the model’s output to follow a user-specified template with placeholders.,The user supplies a template and defines placeholder syntax. The model fills the placeholders with appropriate content while preserving the rest of the template’s structure and formatting.,"[{""name"": ""placeholder_syntax_X"", ""description"": ""Description of how placeholders are represented (e.g. CAPITALIZED WORDS, '<placeholder>', '{FIELD_NAME}')."", ""required"": true}, {""name"": ""template_pattern"", ""description"": ""The actual template text that should be preserved."", ""required"": true}]","[{""name"": ""filled_template"", ""description"": ""The template with placeholders replaced by appropriate content.""}]","{""phases"": [{""name"": ""template_parsing"", ""description"": ""Model identifies all placeholders within the template.""}, {""name"": ""content_generation_for_placeholders"", ""description"": ""Model generates content for each placeholder based on instructions and user context.""}, {""name"": ""template_reassembly"", ""description"": ""Model reassembles the full template with filled placeholders.""}]}","{""allow_partial_fill"": ""If true, the model can leave some placeholders untouched (e.g. for later editing)."", ""preserve_whitespace"": ""If true, whitespace and layout must be preserved exactly.""}","[""Generating structured reports or letters."", ""Producing LaTeX, Markdown, or HTML skeletons filled with research content."", ""Creating consistent document formats across a dataset.""]","[""Model may alter or drop parts of the template if not explicitly constrained."", ""Incorrectly inferred meaning of ambiguous placeholders."", ""Overfitting content to a template that does not quite fit the task.""]","I will give you a template. {placeholder_syntax_X} are placeholders that you must fill.

Template:
{template_pattern}

Fill in each placeholder with appropriate content based on my instructions. Preserve all other text and formatting exactly."
Chain-of-Thought,reasoning,Improve reasoning quality by making the model explicitly walk through intermediate steps before giving a final answer.,"The prompt instructs the model to break down a task into logical steps, reason through them, and only then present a final answer. Reasoning can be formatted as numbered steps, bullet lists, or short paragraphs.","[{""name"": ""task_description"", ""description"": ""Problem or question that requires multi-step reasoning."", ""required"": true}, {""name"": ""reasoning_style"", ""description"": ""Preferred style for intermediate steps (e.g. 'numbered steps', 'brief bullet points', 'detailed algebraic derivation')."", ""required"": false}, {""name"": ""max_steps_hint"", ""description"": ""Optional guidance on how many steps to use before concluding."", ""required"": false}]","[{""name"": ""reasoning_steps"", ""description"": ""Sequence of intermediate steps or thoughts leading to a conclusion.""}, {""name"": ""final_answer"", ""description"": ""The final statement or result after the reasoning steps.""}]","{""phases"": [{""name"": ""problem_restating"", ""description"": ""Model restates the task to ensure understanding.""}, {""name"": ""stepwise_reasoning"", ""description"": ""Model decomposes the problem into steps and solves each step.""}, {""name"": ""answer_extraction"", ""description"": ""Model summarizes the result as a concise final answer.""}]}","{""hide_reasoning_from_user"": ""Whether to show reasoning steps to the user or keep them internal."", ""max_reasoning_length"": ""Limit on the total length of the reasoning trace.""}","[""Mathematical proofs and derivations."", ""Complex research questions that involve multiple constraints."", ""Logical puzzles and planning problems.""]","[""Model can produce plausible but incorrect reasoning chains."", ""Exposing full chains to users can make errors look more convincing."", ""Long reasoning traces can be slow and costly.""]","You are an expert assistant.
For the following task, think through the problem step by step before giving your final answer.

Task: {task_description}

{% if reasoning_style %}Use this style for your reasoning: {reasoning_style}
{% endif %}
First list your reasoning steps. Then, on a new line, write 'Final answer:' followed by your conclusion."

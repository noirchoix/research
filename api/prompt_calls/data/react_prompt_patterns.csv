pattern_name,pattern_family,primary_purpose,core_mechanism,input_fields,output_fields,workflow_structure,control_flags,typical_use_cases,risks_and_misuses,example_prompt_skeleton,notes
ReAct – Knowledge QA (Dense Reason + Act),Reason+Action / Tool-Augmented QA,"Answer knowledge-intensive questions by interleaving chain-of-thought reasoning with explicit tool calls (Search, Lookup, Finish) against an external knowledge source such as Wikipedia.","The model alternates between free-form reasoning steps (Thought) and symbolic actions (Action) that query an external environment. Each Action produces an Observation, which is appended to the context and used in subsequent Thoughts. The trajectory follows the pattern:

Question → [Thought → Action → Observation]×k → Finish[answer].

Thoughts decompose the problem, choose what to retrieve next, interpret observations, and synthesize the final answer, while Actions handle concrete retrieval via a restricted API (e.g. Search[entity], Lookup[string], Finish[answer]).","[{""name"": ""task_instruction"", ""description"": ""High-level natural-language description of the task, e.g. \""You are an agent that answers questions by reasoning and by calling a Wikipedia API with Search[], Lookup[], Finish[].\"""", ""required"": true}, {""name"": ""action_space_spec"", ""description"": ""Formal description of allowed actions and their syntax, e.g. Search[entity], Lookup[string], Finish[answer], plus what each returns."", ""required"": true}, {""name"": ""format_spec"", ""description"": ""Textual format contract for the trajectory, typically: Question, Thought k, Action k, Observation k, followed by a final Finish[]."", ""required"": true}, {""name"": ""few_shot_trajectories"", ""description"": ""1–6 fully written ReAct trajectories that show alternation of Thought / Action / Observation until Finish[answer]. Each example uses real calls to the environment and correct final answers."", ""required"": true}, {""name"": ""query_or_claim"", ""description"": ""The user’s question or fact-checking claim to solve in the new instance."", ""required"": true}, {""name"": ""step_budget"", ""description"": ""Maximum number of Thought/Action steps before the model must call Finish[]. Used to prevent infinite loops."", ""required"": false}, {""name"": ""style_or_safety_instructions"", ""description"": ""Optional guardrails on style (e.g. concise final answer only) and on tool usage (e.g. stay within domain, don’t call disallowed URLs)."", ""required"": false}]","[{""name"": ""reasoning_trace"", ""description"": ""Full interleaved sequence of Thought, Action, and Observation steps used to arrive at the answer.""}, {""name"": ""tool_calls"", ""description"": ""Structured representation of each Action (name, arguments, step index), usable for logging or execution.""}, {""name"": ""tool_observations"", ""description"": ""Text returned by each tool call, appended to context as Observation k.""}, {""name"": ""final_answer"", ""description"": ""The argument of the last Finish[answer] action, or the answer extracted from it; this is what is shown to the end-user.""}]","{""phases"": [{""name"": ""setup"", ""description"": ""Explain the task, define the action space, and show 1–6 complete ReAct example trajectories (Question → Thought/Action/Observation → Finish).""}, {""name"": ""initial_reasoning"", ""description"": ""For a new Question/Claim, generate Thought 1 that decomposes the task and decides the first Action (usually a Search[...]).""}, {""name"": ""reason_act_loop"", ""description"": ""Alternate between Thought k and Action k. After each tool call, inject Observation k (the tool result) into the context. Thoughts use both internal knowledge and observations to decide the next tool call or to conclude with Finish[answer].""}, {""name"": ""termination"", ""description"": ""When sufficient evidence is gathered or the step budget is reached, issue Finish[answer]. Extract the answer and optionally strip the ReAct trace for user-facing display.""}, {""name"": ""optional_backoff"", ""description"": ""If the model fails to reach Finish[answer] in the allotted steps, or appears uncertain, fall back to a pure CoT (self-consistency) prompt or vice versa (CoT → ReAct) as described in the paper.""}]}","{""max_steps"": ""Integer limit on Thought/Action pairs (e.g. 5–7)."", ""allowed_actions"": [""Search[...]"", ""Lookup[...]"", ""Finish[...]""], ""must_follow_format"": true, ""allow_free_text_between_actions"": false, ""stop_on_finish"": true, ""external_env_guardrails"": ""Environment is restricted (e.g. only Wikipedia API) and sandboxed to avoid unsafe browsing or side-effects.""}","[""Multi-hop question answering using external corpora (e.g. Wikipedia)."", ""Fact verification tasks (SUPPORTS / REFUTES / NOT ENOUGH INFO)."", ""Any task where internal model knowledge is insufficient or may be outdated.""]","[""Reasoning loops where the model repeats the same Search/Lookup steps."", ""Over-reliance on weak retrieval APIs leading to errors when search results are poor."", ""Long trajectories that increase latency and cost."", ""Possible misuse if the external environment is not sandboxed (privacy / safety issues).""]","You are an intelligent agent that can **think** and **act** to answer questions.
You have access to a Wikipedia API with the following actions:
  • Search[entity]: returns the first 5 sentences of the page for `entity`, or
    suggested similar entities if it does not exist.
  • Lookup[string]: returns the next sentence in the current page that contains `string`.
  • Finish[answer]: stop and return `answer`.

For each problem, use the following format:
Question: <user question>
Thought 1: <explain what you will do first>
Action 1: Search[...]
Observation 1: <result from the search API>
Thought 2: <update plan based on Observation 1>
Action 2: Lookup[...] or Search[...]
Observation 2: <result>
... (repeat Thought/Action/Observation as needed) ...
Thought k: <I now know the answer because ...>
Action k: Finish[final answer]

Here are some examples:
<insert 3–6 fully written ReAct trajectories from the paper or your own data>

Now answer this new question using the same format.
Question: {question}
Thought 1:","This is the canonical ReAct pattern for knowledge-intensive tasks: Thoughts are dense (appearing before almost every Action), and the action space is small and tool-like. It explicitly separates internal reasoning from external retrieval, which improves factuality and interpretability over pure CoT, while avoiding the blind exploration of act-only agents."
ReAct – Decision Environment (Sparse Reason + Act),Reason+Action / Interactive Decision-Making,"Control agents in interactive environments (games, web UIs, robots) by allowing the model to interleave high-level natural-language reasoning with low-level domain actions.","Use a large language model as a policy over an **augmented action space** that includes both environment actions (go, open, take, click, buy, clean, etc.) and language thoughts (think: ...). Observations from the environment are converted to text and appended to the context. Thoughts are **sparse**: the model chooses when to insert them to decompose goals, track progress, decide next subgoals, or reflect on what to do next.","[{""name"": ""task_instruction"", ""description"": ""Natural-language description of the high-level goal in the environment, e.g. \""Your task is to put a clean lettuce on the dining table.\"""", ""required"": true}, {""name"": ""environment_description"", ""description"": ""A brief description of the world, objects, and what actions are possible, e.g. textual room description, list of visible objects, or a web UI schema."", ""required"": true}, {""name"": ""action_space_spec"", ""description"": ""Catalog of environment actions and their syntax, e.g. go to OBJ, open OBJ, take OBJ from SRC, clean OBJ with TOOL, search QUERY, click ID, buy, etc."", ""required"": true}, {""name"": ""format_spec"", ""description"": ""Turn-taking format: each line begins with either an environment event or an agent event, e.g.\n  > think: ...\n  > go to fridge 1\n  Observation: The fridge 1 is closed.\n  > open fridge 1\n  Observation: ...\nuntil the goal is satisfied."", ""required"": true}, {""name"": ""few_shot_trajectories"", ""description"": ""1–3 demonstrations per task type showing how the agent decomposes goals with occasional think: lines and uses environment actions to complete tasks."", ""required"": true}, {""name"": ""max_action_budget"", ""description"": ""Optional limit on the total number of environment actions to avoid unbounded exploration."", ""required"": false}]","[{""name"": ""action_trajectory"", ""description"": ""Sequence of issued actions (with arguments) from start to success or failure.""}, {""name"": ""reasoning_trace"", ""description"": ""Sparse think: lines that show goal decomposition, progress tracking, and commonsense reasoning about the environment.""}, {""name"": ""final_env_state"", ""description"": ""Textual description of the environment when the agent finishes (success/fail).""}]","{""phases"": [{""name"": ""initial_goal_decomposition"", ""description"": ""Emit a think: line that breaks the high-level goal into subgoals (e.g. find lettuce → clean lettuce → place lettuce on table).""}, {""name"": ""exploration_and_subgoal_execution"", ""description"": ""Use environment actions (go/open/take/clean/etc.) to achieve the current subgoal. Insert think: lines when helpful to choose likely locations, update which subgoal is active, or re-plan.""}, {""name"": ""progress_tracking"", ""description"": ""Periodically summarize in think: what has been accomplished and what remains e.g. \""Now I have taken the lettuce. Next, I need to go to the sink.\""""}, {""name"": ""termination"", ""description"": ""Stop when the environment signals success (goal satisfied) or when the action budget is consumed. Optionally emit a final think: summary.""}]}","{""max_actions"": ""Hard limit on action count (distinct from think: lines)."", ""allow_think_lines"": true, ""think_prefix"": ""think:"", ""must_obey_action_grammar"": true, ""stop_on_success_signal"": true}","[""Text-based games and embodied household tasks (e.g. ALFWorld)."", ""Web navigation / shopping environments (e.g. WebShop)."", ""Any environment where actions are discrete and observations can be textualized.""]","[""Getting stuck in local loops (e.g. repeatedly trying an impossible action)."", ""Incorrect commonsense assumptions about where objects are or what actions do."", ""Costs from long trajectories in large environments."", ""If connected to real systems (e.g. real shopping carts or robots), unsafe or undesired actions without additional safety layers.""]","You are an agent acting in a text environment. You can **think** in natural language and **act** using environment commands.

Format:
Environment: <initial room / web page description>
Your task is to: {task_instruction}
> think: <describe your subgoal or plan>
> <action 1>
Observation: <result of action 1>
> think: <update plan if needed>
> <action 2>
Observation: <result of action 2>
... (continue) ...
(Stop when the task is complete.)

Here are some examples:
<insert 1–3 trajectories per task type, showing sparse think: lines>

Now solve this new task using the same format.
Environment: {env_description}
Your task is to: {task_instruction}","Compared to the QA variant, Thoughts here are sparse—often only at key decision points—because trajectories can be long (tens of actions). The pattern is well suited for few-shot prompting in structured environments and can outperform pure imitation / RL baselines when demonstrations are limited."
